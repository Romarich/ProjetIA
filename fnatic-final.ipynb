{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**European Soccer Database Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "from array import *\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première étape : Fetch\n",
    "\n",
    "On récupère les différentes tables nécéssaires dans la DB et on les fusionne pour ne faire qu'une seule table. Nous avons bien sûr pris la table des matchs, c'est la base même de la prédiction. Nous avons ensuite ajouté la table player attributes, qui regroupe les différentes statistiques utiles à propos des joueurs présents sur le terrain. En effet, la présence d'un bon joueur influe de façon évidente sur le résultat du match. Pour cela pour pas compliquer trop les choses nous avons choisi de prendre que la cote de potentiel des joueurs ainsi que leur overall rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryBuilder(lettre, df, team, table):\n",
    "    for element in range(1,12):\n",
    "        queryAExecuter = \"SELECT x.id,x.date,\"\n",
    "        queryAExecuter = queryAExecuter +lettre+str(element)+\".potential, \"+ lettre+str(element)+\".overall_rating,MAX(\"+lettre+str(element)+\".date)\"\n",
    "        queryAExecuter = queryAExecuter + \" FROM \" + table + \" x \"                \n",
    "        queryAExecuter = queryAExecuter + \" LEFT JOIN Player_Attributes \"+lettre+str(element)+\" ON \"+lettre+str(element)+\".player_api_id = x.\"+team+\"_player_\"+str(element)+\" AND \"+ lettre +str(element)+\".date <= x.date\"\n",
    "        queryAExecuter = queryAExecuter + \" GROUP BY x.id ORDER BY x.date \"\n",
    "        queryEnCours = dat.execute(queryAExecuter)\n",
    "        colsEnCours = [column[0] for column in queryEnCours.description]\n",
    "        ncols = []\n",
    "        for i, name in enumerate(colsEnCours):\n",
    "            if i!=0 and i!=1:\n",
    "                ncols.append(name + \"_\" + team + str(element))\n",
    "                colsEnCours[i] = name + \"_\" + team + str(element)\n",
    "            else:\n",
    "                ncols.append(name)\n",
    "        dataFrameEnCours = pd.DataFrame.from_records(data = queryEnCours.fetchall(), columns = ncols)\n",
    "        dataFrameEnCours.fillna(-50)\n",
    "        dataFrameEnCours = dataFrameEnCours.drop(columns = ['id','date'])\n",
    "        for i, name in enumerate(colsEnCours):\n",
    "            if name != 'id' and name != 'date':\n",
    "                df.insert(2, name, dataFrameEnCours[name], True) \n",
    "        del dataFrameEnCours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc créé une fonction queryBuilder avec quatres paramètres afin de ne pas avoir du code repetitif pour la création des query pour les caractéristiques des joueurs, qu'ils soient chez eux ou en déplacements. Cela permet aussi de faire exactement les mêmes modifications, que ce soit sur la table de Test ou la table de Train.\n",
    "\n",
    "Nous n'avons pas rajouté la table Joueur car nous avons remarqué qu'au final tous les joueurs sont des sportifs du coup le poids des joueurs ainsi que leur taille n'influence en rien l'équipe , leur age non plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = sqlite3.connect('/kaggle/input/jvm000001/database/database.sqlite')\n",
    "\n",
    "table = [\"Country\", \"League\", \"X_Train\", \"Player\", \"Player_Attributes\", \n",
    "         \"Team\", \"Team_Attributes\"]\n",
    "queryTeamAttributes = dat.execute(\"SELECT * FROM Team_Attributes\")\n",
    "queryTrain = \"SELECT x.* FROM X_train x\"\n",
    "queryXTrain = dat.execute(queryTrain) \n",
    "colsXTrain = [column[0] for column in queryXTrain.description]\n",
    "X_train = pd.DataFrame.from_records(data = queryXTrain.fetchall(), columns = colsXTrain)\n",
    "queryXTest = dat.execute(\"SELECT * FROM X_test\") \n",
    "colsXTest = [column[0] for column in queryXTest.description]\n",
    "X_test = pd.DataFrame.from_records(data = queryXTest.fetchall(), columns = colsXTest)\n",
    "queryBuilder('a',X_train,'home',\"X_train\")\n",
    "queryBuilder('b',X_train,'away',\"X_train\")\n",
    "queryBuilder('a',X_test,'home',\"X_test\")\n",
    "queryBuilder('b',X_test,'away',\"X_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of        index     id MAX(b11.date)_away11  overall_rating_away11  \\\n",
      "0          0  11103                 None                    NaN   \n",
      "1          1  16167                 None                    NaN   \n",
      "2          2  11222                 None                    NaN   \n",
      "3          3  11018                 None                    NaN   \n",
      "4          4  25596                 None                    NaN   \n",
      "...      ...    ...                  ...                    ...   \n",
      "20474  20474   3902  2016-05-19 00:00:00                   74.0   \n",
      "20475  20475  13531  2015-10-30 00:00:00                   67.0   \n",
      "20476  20476  15802  2016-02-04 00:00:00                   74.0   \n",
      "20477  20477  23728  2015-09-21 00:00:00                   74.0   \n",
      "20478  20478   3255  2016-03-03 00:00:00                   54.0   \n",
      "\n",
      "       potential_away11 MAX(b10.date)_away10  overall_rating_away10  \\\n",
      "0                   NaN                 None                    NaN   \n",
      "1                   NaN                 None                    NaN   \n",
      "2                   NaN                 None                    NaN   \n",
      "3                   NaN                 None                    NaN   \n",
      "4                   NaN                 None                    NaN   \n",
      "...                 ...                  ...                    ...   \n",
      "20474              80.0  2015-09-25 00:00:00                   74.0   \n",
      "20475              67.0  2015-10-09 00:00:00                   66.0   \n",
      "20476              74.0  2016-04-14 00:00:00                   68.0   \n",
      "20477              74.0  2015-10-09 00:00:00                   72.0   \n",
      "20478              61.0  2016-04-21 00:00:00                   52.0   \n",
      "\n",
      "       potential_away10   MAX(b9.date)_away9  overall_rating_away9  ...  \\\n",
      "0                   NaN                 None                   NaN  ...   \n",
      "1                   NaN                 None                   NaN  ...   \n",
      "2                   NaN                 None                   NaN  ...   \n",
      "3                   NaN                 None                   NaN  ...   \n",
      "4                   NaN                 None                   NaN  ...   \n",
      "...                 ...                  ...                   ...  ...   \n",
      "20474              74.0  2015-10-23 00:00:00                  61.0  ...   \n",
      "20475              66.0  2016-03-10 00:00:00                  68.0  ...   \n",
      "20476              69.0  2016-04-14 00:00:00                  70.0  ...   \n",
      "20477              72.0  2015-10-16 00:00:00                  75.0  ...   \n",
      "20478              65.0  2016-03-10 00:00:00                  69.0  ...   \n",
      "\n",
      "       away_player_2 away_player_3  away_player_4  away_player_5  \\\n",
      "0           231753.0       24235.0        41884.0        34320.0   \n",
      "1            13515.0       13533.0        69261.0            NaN   \n",
      "2           150466.0       18500.0        25815.0        41380.0   \n",
      "3            27720.0       24235.0        41884.0        41892.0   \n",
      "4            67349.0       16254.0        25815.0        25843.0   \n",
      "...              ...           ...            ...            ...   \n",
      "20474        30509.0       39027.0        30459.0        31291.0   \n",
      "20475            NaN           NaN            NaN            NaN   \n",
      "20476            NaN           NaN        68744.0            NaN   \n",
      "20477       213820.0       42312.0        30276.0        37484.0   \n",
      "20478        23369.0       40695.0        38899.0        47418.0   \n",
      "\n",
      "      away_player_6  away_player_7  away_player_8 away_player_9  \\\n",
      "0           31314.0       192574.0        27694.0       39232.0   \n",
      "1           69599.0            NaN            NaN           NaN   \n",
      "2           39701.0        39264.0        73999.0      167634.0   \n",
      "3           31314.0        33888.0        41890.0       39232.0   \n",
      "4           93223.0       113227.0       302079.0       30912.0   \n",
      "...             ...            ...            ...           ...   \n",
      "20474       40196.0        36615.0        33991.0       37459.0   \n",
      "20475           NaN            NaN            NaN           NaN   \n",
      "20476           NaN         2625.0            NaN           NaN   \n",
      "20477       24132.0        46836.0        75619.0       25462.0   \n",
      "20478       32148.0        23253.0        24411.0       24773.0   \n",
      "\n",
      "       away_player_10  away_player_11  \n",
      "0             30712.0         39540.0  \n",
      "1                 NaN             NaN  \n",
      "2             39306.0         96598.0  \n",
      "3             30727.0         39540.0  \n",
      "4             25860.0         71764.0  \n",
      "...               ...             ...  \n",
      "20474         26181.0         15403.0  \n",
      "20475             NaN             NaN  \n",
      "20476             NaN             NaN  \n",
      "20477         39834.0         41294.0  \n",
      "20478         33881.0         30830.0  \n",
      "\n",
      "[20479 rows x 144 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deuxième étape : Clean\n",
    "\n",
    "Nous retirons les différentes colonnes qui ne concernent pas directement le jeu lui même. Comme par exemple : la ville d'origine de l'équipe etc, sont des facteurs qui n'influencent que très peu les résultats, voir pas dutout. Il est important de se focaliser d'abord sur les informations les plus importantes.\n",
    "\n",
    "Dans les attributs d'équipes, nous avons aussi retiré les class car nous pensons que des chiffres sont bien plus précis que des noms de class.\n",
    "\n",
    "Nous n'avons pas supprimé dans X_train les colonnes de joueur avec leur position X et Y car nous pensons qu'il est interessant de savoir la position de la personne car certaines d'entre elles sont plus forte dans une position qu'une autre.\n",
    "\n",
    "Nous préparons les informations afin qu'elles soient plus faciles à utiliser. Au niveau du prepare certaines préparations sont aussi faites dans le queryBuilder car on souhaitait d'abord nettoyer et préparer les informations avant de les rajouter dans notre X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['season','date','league_id','country_id'])\n",
    "for x in range(1,12):\n",
    "    X_train = X_train.drop(columns=[\"MAX(a\"+str(x)+\".date)_home\"+str(x)])\n",
    "    X_train = X_train.drop(columns=[\"MAX(b\"+str(x)+\".date)_away\"+str(x)])\n",
    "for x in range(1,12):\n",
    "    X_test = X_test.drop(columns=[\"MAX(a\"+str(x)+\".date)_home\"+str(x)])\n",
    "    X_test = X_test.drop(columns=[\"MAX(b\"+str(x)+\".date)_away\"+str(x)])\n",
    "X_test = X_test.drop(columns=['season','date','league_id','country_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troisième étape : Prepare\n",
    "\n",
    "Nous préparons les informations afin qu'elles soient plus faciles à utiliser. Au niveau du prepare certaines préparations sont aussi faites dans le queryBuilder car nous souhaitions d'abord nettoyer et préparer les informations avant de les rajouter dans notre X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(-9999)\n",
    "X_test = X_test.fillna(-9999)\n",
    "labels_catA = X_train[\"home_team_goal\"]\n",
    "labels_catB = X_train[\"away_team_goal\"]\n",
    "labels_num = [None]* len(X_train.index)\n",
    "for index,rows in X_train.iterrows():\n",
    "    y= rows[\"home_team_goal\"]\n",
    "    z= rows[\"away_team_goal\"]\n",
    "    if y > z:\n",
    "        labels_num[index] = 1\n",
    "    elif y < z:\n",
    "        labels_num[index] = -1\n",
    "    else :\n",
    "        labels_num[index] = 0\n",
    "\n",
    "X_train = X_train.drop(columns=['home_team_goal','away_team_goal']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le contenu au niveau des colonnes de notre table X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20479 entries, 0 to 20478\n",
      "Data columns (total 116 columns):\n",
      "index                    int64\n",
      "id                       int64\n",
      "overall_rating_away11    float64\n",
      "potential_away11         float64\n",
      "overall_rating_away10    float64\n",
      "potential_away10         float64\n",
      "overall_rating_away9     float64\n",
      "potential_away9          float64\n",
      "overall_rating_away8     float64\n",
      "potential_away8          float64\n",
      "overall_rating_away7     float64\n",
      "potential_away7          float64\n",
      "overall_rating_away6     float64\n",
      "potential_away6          float64\n",
      "overall_rating_away5     float64\n",
      "potential_away5          float64\n",
      "overall_rating_away4     float64\n",
      "potential_away4          float64\n",
      "overall_rating_away3     float64\n",
      "potential_away3          float64\n",
      "overall_rating_away2     float64\n",
      "potential_away2          float64\n",
      "overall_rating_away1     float64\n",
      "potential_away1          float64\n",
      "overall_rating_home11    float64\n",
      "potential_home11         float64\n",
      "overall_rating_home10    float64\n",
      "potential_home10         float64\n",
      "overall_rating_home9     float64\n",
      "potential_home9          float64\n",
      "overall_rating_home8     float64\n",
      "potential_home8          float64\n",
      "overall_rating_home7     float64\n",
      "potential_home7          float64\n",
      "overall_rating_home6     float64\n",
      "potential_home6          float64\n",
      "overall_rating_home5     float64\n",
      "potential_home5          float64\n",
      "overall_rating_home4     float64\n",
      "potential_home4          float64\n",
      "overall_rating_home3     float64\n",
      "potential_home3          float64\n",
      "overall_rating_home2     float64\n",
      "potential_home2          float64\n",
      "overall_rating_home1     float64\n",
      "potential_home1          float64\n",
      "stage                    int64\n",
      "match_api_id             int64\n",
      "home_team_api_id         int64\n",
      "away_team_api_id         int64\n",
      "home_player_X1           float64\n",
      "home_player_X2           float64\n",
      "home_player_X3           float64\n",
      "home_player_X4           float64\n",
      "home_player_X5           float64\n",
      "home_player_X6           float64\n",
      "home_player_X7           float64\n",
      "home_player_X8           float64\n",
      "home_player_X9           float64\n",
      "home_player_X10          float64\n",
      "home_player_X11          float64\n",
      "away_player_X1           float64\n",
      "away_player_X2           float64\n",
      "away_player_X3           float64\n",
      "away_player_X4           float64\n",
      "away_player_X5           float64\n",
      "away_player_X6           float64\n",
      "away_player_X7           float64\n",
      "away_player_X8           float64\n",
      "away_player_X9           float64\n",
      "away_player_X10          float64\n",
      "away_player_X11          float64\n",
      "home_player_Y1           float64\n",
      "home_player_Y2           float64\n",
      "home_player_Y3           float64\n",
      "home_player_Y4           float64\n",
      "home_player_Y5           float64\n",
      "home_player_Y6           float64\n",
      "home_player_Y7           float64\n",
      "home_player_Y8           float64\n",
      "home_player_Y9           float64\n",
      "home_player_Y10          float64\n",
      "home_player_Y11          float64\n",
      "away_player_Y1           float64\n",
      "away_player_Y2           float64\n",
      "away_player_Y3           float64\n",
      "away_player_Y4           float64\n",
      "away_player_Y5           float64\n",
      "away_player_Y6           float64\n",
      "away_player_Y7           float64\n",
      "away_player_Y8           float64\n",
      "away_player_Y9           float64\n",
      "away_player_Y10          float64\n",
      "away_player_Y11          float64\n",
      "home_player_1            float64\n",
      "home_player_2            float64\n",
      "home_player_3            float64\n",
      "home_player_4            float64\n",
      "home_player_5            float64\n",
      "home_player_6            float64\n",
      "home_player_7            float64\n",
      "home_player_8            float64\n",
      "home_player_9            float64\n",
      "home_player_10           float64\n",
      "home_player_11           float64\n",
      "away_player_1            float64\n",
      "away_player_2            float64\n",
      "away_player_3            float64\n",
      "away_player_4            float64\n",
      "away_player_5            float64\n",
      "away_player_6            float64\n",
      "away_player_7            float64\n",
      "away_player_8            float64\n",
      "away_player_9            float64\n",
      "away_player_10           float64\n",
      "away_player_11           float64\n",
      "dtypes: float64(110), int64(6)\n",
      "memory usage: 18.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info(verbose = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of        index     id  overall_rating_away11  potential_away11  \\\n",
      "0          0  11103                -9999.0           -9999.0   \n",
      "1          1  16167                -9999.0           -9999.0   \n",
      "2          2  11222                -9999.0           -9999.0   \n",
      "3          3  11018                -9999.0           -9999.0   \n",
      "4          4  25596                -9999.0           -9999.0   \n",
      "...      ...    ...                    ...               ...   \n",
      "20474  20474   3902                   74.0              80.0   \n",
      "20475  20475  13531                   67.0              67.0   \n",
      "20476  20476  15802                   74.0              74.0   \n",
      "20477  20477  23728                   74.0              74.0   \n",
      "20478  20478   3255                   54.0              61.0   \n",
      "\n",
      "       overall_rating_away10  potential_away10  overall_rating_away9  \\\n",
      "0                    -9999.0           -9999.0               -9999.0   \n",
      "1                    -9999.0           -9999.0               -9999.0   \n",
      "2                    -9999.0           -9999.0               -9999.0   \n",
      "3                    -9999.0           -9999.0               -9999.0   \n",
      "4                    -9999.0           -9999.0               -9999.0   \n",
      "...                      ...               ...                   ...   \n",
      "20474                   74.0              74.0                  61.0   \n",
      "20475                   66.0              66.0                  68.0   \n",
      "20476                   68.0              69.0                  70.0   \n",
      "20477                   72.0              72.0                  75.0   \n",
      "20478                   52.0              65.0                  69.0   \n",
      "\n",
      "       potential_away9  overall_rating_away8  potential_away8  ...  \\\n",
      "0              -9999.0               -9999.0          -9999.0  ...   \n",
      "1              -9999.0               -9999.0          -9999.0  ...   \n",
      "2              -9999.0               -9999.0          -9999.0  ...   \n",
      "3              -9999.0               -9999.0          -9999.0  ...   \n",
      "4              -9999.0               -9999.0          -9999.0  ...   \n",
      "...                ...                   ...              ...  ...   \n",
      "20474             68.0                  61.0             74.0  ...   \n",
      "20475             81.0                  66.0             70.0  ...   \n",
      "20476             70.0                  56.0             66.0  ...   \n",
      "20477             76.0                  65.0             75.0  ...   \n",
      "20478             69.0                  59.0             68.0  ...   \n",
      "\n",
      "       away_player_2  away_player_3  away_player_4  away_player_5  \\\n",
      "0           231753.0        24235.0        41884.0        34320.0   \n",
      "1            13515.0        13533.0        69261.0        -9999.0   \n",
      "2           150466.0        18500.0        25815.0        41380.0   \n",
      "3            27720.0        24235.0        41884.0        41892.0   \n",
      "4            67349.0        16254.0        25815.0        25843.0   \n",
      "...              ...            ...            ...            ...   \n",
      "20474        30509.0        39027.0        30459.0        31291.0   \n",
      "20475        -9999.0        -9999.0        -9999.0        -9999.0   \n",
      "20476        -9999.0        -9999.0        68744.0        -9999.0   \n",
      "20477       213820.0        42312.0        30276.0        37484.0   \n",
      "20478        23369.0        40695.0        38899.0        47418.0   \n",
      "\n",
      "       away_player_6  away_player_7  away_player_8  away_player_9  \\\n",
      "0            31314.0       192574.0        27694.0        39232.0   \n",
      "1            69599.0        -9999.0        -9999.0        -9999.0   \n",
      "2            39701.0        39264.0        73999.0       167634.0   \n",
      "3            31314.0        33888.0        41890.0        39232.0   \n",
      "4            93223.0       113227.0       302079.0        30912.0   \n",
      "...              ...            ...            ...            ...   \n",
      "20474        40196.0        36615.0        33991.0        37459.0   \n",
      "20475        -9999.0        -9999.0        -9999.0        -9999.0   \n",
      "20476        -9999.0         2625.0        -9999.0        -9999.0   \n",
      "20477        24132.0        46836.0        75619.0        25462.0   \n",
      "20478        32148.0        23253.0        24411.0        24773.0   \n",
      "\n",
      "       away_player_10  away_player_11  \n",
      "0             30712.0         39540.0  \n",
      "1             -9999.0         -9999.0  \n",
      "2             39306.0         96598.0  \n",
      "3             30727.0         39540.0  \n",
      "4             25860.0         71764.0  \n",
      "...               ...             ...  \n",
      "20474         26181.0         15403.0  \n",
      "20475         -9999.0         -9999.0  \n",
      "20476         -9999.0         -9999.0  \n",
      "20477         39834.0         41294.0  \n",
      "20478         33881.0         30830.0  \n",
      "\n",
      "[20479 rows x 116 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On separe notre Dataframe de train et les prédictions déjà connu en train et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(X_train, labels_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons commencé par un Modèle Logistic Regression car il nous semblait être le plus simple à mettre en place afin de pouvoir tester le plus facilement.\n",
    "Malheureusement nous avons remarqué que même avec de l'optimisation de paramètre avec un gridSearch ou ne depassait pas les 47%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy logistic regression=  0.351171875\n"
     ]
    }
   ],
   "source": [
    "log_reg = SGDClassifier(loss='log', max_iter=5, tol=-np.infty, random_state=42)\n",
    "#log_reg = SGDClassifier(alpha= 0.001,fit_intercept= False,l1_ratio= 1, loss='log', max_iter=5, n_jobs= -1, penalty= 'l1', random_state= 42, tol=-np.infty)\n",
    "log_reg.fit(features_train, labels_train)\n",
    "labels_pred = log_reg.predict(features_test)\n",
    "accuracy_log = accuracy_score(labels_test, labels_pred)\n",
    "print (\"Accuracy logistic regression= \", accuracy_log)\n",
    "\n",
    "#ici on fait la prediction avec \n",
    "labels_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est pour cela que nous avons changé et nous sommes parti vers du KNN. En y réfléchissant, nous nous sommes dit que vu que la sortie de notre modèle est soit 0,-1 ou 1, le KNN peut etre une bonne idée vu que celui-ci crée des groupes donc nous avons décidé de l'implémenter. Au début du code ci-dessous, nous avons fait une boucle for qui permet de rechercher quel est le meilleur nombre de voisins K afin de savoir avec combien de valeurs notre modèle va la comparer avant de faire sa prédiction. Nous avons d'abord commencé par 40 puis après nous avons augmenté petit à petit car nous avions remarqué que lorsque nous mettions de 1 à 40 non compris il prenait 39. Nous nous sommes alors dit qu'il y avait surement moyen d'avoir un K plus haut qui serait mieux pour notre modèle. Nous avons ensuite testé 100 puis 200 et nous avons fini avec 300. Lorsque nous avons testé le 300, le k le plus haut était 253. Nous pensions que nous avions atteint le maximum. Et nous l'avons verifié dans le GridSearchCV qui est un peu plus bas et c'est bien le 253 qui est le meilleur. Certes c'est une grosse valeur mais cela permet d'être plus précis et niveau des performances et du temps cela ne prend pas spécialement beaucoup plus de temps. Nous sommes donc arrivé à une accuracy de 0.482482."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie de code qui suit prend pas mal de temps.\n",
    "La console affiche donc ceci :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbDeVoisins = [i for i in range(1, 300, 2)]\n",
    "scores = []\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for k in nbDeVoisins:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k,weights='uniform',metric='manhattan')\n",
    "    score = cross_val_score(knn, features_train, labels_train, cv=5)\n",
    "    scores.append(score.mean())\n",
    "    print(k)\n",
    "\n",
    "k_optimal_pour_knn = nbDeVoisins[scores.index(max(scores))]\n",
    "print(\"Optimal k = \" + k_optimal_pour_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on a donc le GridSearch qui va nous permettre de trouver les meilleurs paramètres pour notre Modèle de Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3713132365388372\n",
      "{'alpha': 0.001, 'fit_intercept': False, 'l1_ratio': 1, 'loss': 'log', 'max_iter': 5, 'n_jobs': -1, 'penalty': 'l1', 'random_state': 42, 'tol': -inf}\n"
     ]
    }
   ],
   "source": [
    "parametres = [{'loss':['log'], 'max_iter':[5], 'tol': [-np.infty], 'random_state':[42]},{'penalty' : ['none','l1', 'l2', 'elasticnet'],'alpha': [0.001],\n",
    "    'l1_ratio': [1],'loss': ['log'],'fit_intercept' : [False,True], 'max_iter' : [5],'tol' : [-np.infty], 'n_jobs' : [-1], 'random_state' : [42]}]\n",
    "grid_search = GridSearchCV(estimator = log_reg,\n",
    "                          param_grid = parametres,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "grid_search = grid_search.fit(features_train, labels_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on a donc le code qui contient notre modèle avec justement nos 253 voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy du KNN =  0.4462890625\n"
     ]
    }
   ],
   "source": [
    "optimal_knn = KNeighborsClassifier(n_neighbors=253,weights= 'uniform',metric= 'euclidean')\n",
    "# on remarque qu'avec ce cross validation on arrive à un tableau de score qui se rapporche \n",
    "#les un des autres donc cela montre bien que l'on est proche et que l'on a pas d'overfitting du modèle\n",
    "optimal_knn.fit(features_train, labels_train)\n",
    "labels_pred = optimal_knn.predict(features_test)\n",
    "\n",
    "accuracy_KNN = accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "print (\"Accuracy du KNN = \", accuracy_KNN)\n",
    "\n",
    "labels_pred = optimal_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre code pour la gridSearch pour les paramètres optimaux pour notre modèle KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46168370336610454\n",
      "{'metric': 'euclidean', 'n_neighbors': 253, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "parametres = [{'n_neighbors' : [3,5,11,19,253],'weights' : ['uniform','distance'], 'metric':['euclidean','manhattan']}]\n",
    "grid_search = GridSearchCV(estimator = optimal_knn,\n",
    "                          param_grid = parametres,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1)\n",
    "grid_search = grid_search.fit(features_train, labels_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les parties de code ci-dessous nous permettent de mettre notre id de match ainsi que notre prédiction dans un DataFrame et ensuite on le convertit en un fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeToSend = pd.DataFrame()\n",
    "dataframeToSend['id'] = X_test['index']\n",
    "dataframeToSend['classes'] = pd.DataFrame(labels_pred)\n",
    "\n",
    "import os\n",
    "def export_to_csv(df):\n",
    "    #os.remove(\"dataframe.csv\")\n",
    "    df.to_csv('dataframe.csv',index=False)\n",
    "    \n",
    "export_to_csv(dataframeToSend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
